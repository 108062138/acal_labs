{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(-0.0004)\n"
     ]
    }
   ],
   "source": [
    "class my_param_layer(nn.Module):\n",
    "    def __init__(self, B, M, K, N, chunk_row_size, chunk_col_size):\n",
    "        super(my_param_layer, self).__init__()\n",
    "        self.B = B\n",
    "        self.M = M\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.chunk_row_size = chunk_row_size\n",
    "        self.chunk_col_size = chunk_col_size\n",
    "    def my_split(self, A, height, width, dh, dc):\n",
    "        ls = []\n",
    "        for i in range(0, height, dh):\n",
    "            tmp = []\n",
    "            for j in range(0, width, dc):\n",
    "                tmp.append(A[i:i+dh, j:j+dc])\n",
    "            ls.append(tmp)\n",
    "        return ls\n",
    "    def matmul(self, A):\n",
    "        subAs = self.my_split(A, self.M, self.K, self.chunk_row_size, self.chunk_col_size)\n",
    "        subBs = self.my_split(self.B, self.K, self.N, self.chunk_col_size, self.chunk_row_size)\n",
    "\n",
    "        # res = torch.zeros(self.M, self.N)\n",
    "        final_result = []\n",
    "        for i in range(0, self.M//self.chunk_row_size):\n",
    "            row_result = []\n",
    "            for j in range(0, self.N//self.chunk_row_size):\n",
    "                psum = torch.zeros(self.chunk_row_size, self.chunk_row_size)\n",
    "                for k in range(0, self.K//self.chunk_col_size):\n",
    "                    psum += torch.matmul(subAs[i][k], subBs[k][j])\n",
    "                row_result.append(psum)\n",
    "                # res[i*self.chunk_row_size:(i+1)*self.chunk_row_size, j*self.chunk_row_size:(j+1)*self.chunk_row_size] = psum\n",
    "            row_result = torch.cat(row_result, dim = 1)\n",
    "            final_result.append(row_result)\n",
    "        final_result = torch.cat(final_result, dim = 0)\n",
    "        return final_result\n",
    "\n",
    "    def forward(self, A):\n",
    "        return self.matmul(A)\n",
    "\n",
    "M, K, N = 128, 128, 128\n",
    "chunk_row_size, chunk_col_size = 64, 64\n",
    "input = torch.randn(M, K)\n",
    "weight = torch.randn(N, K)\n",
    "model = my_param_layer(weight.t(), M, K, N, chunk_row_size, chunk_col_size)\n",
    "res = model(input)\n",
    "print('loss: ',torch.sum(res - torch.matmul(input, weight.t())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%A : Float(128, 128, strides=[128, 1], requires_grad=0, device=cpu)):\n",
      "  %/Constant_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_1_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_1\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_2_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name=\"/Constant_2\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_3\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Slice_output_0 : Float(64, 128, strides=[128, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/Slice\"](%A, %/Constant_1_output_0, %/Constant_2_output_0, %/Constant_output_0, %/Constant_3_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_4\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_5\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name=\"/Constant_6\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_7\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Slice_1_output_0 : Float(64, 64, strides=[128, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/Slice_1\"](%/Slice_output_0, %/Constant_5_output_0, %/Constant_6_output_0, %/Constant_4_output_0, %/Constant_7_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_8\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name=\"/Constant_9\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={128}, onnx_name=\"/Constant_10\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_11\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Slice_2_output_0 : Float(64, 64, strides=[128, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/Slice_2\"](%/Slice_output_0, %/Constant_9_output_0, %/Constant_10_output_0, %/Constant_8_output_0, %/Constant_11_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_12\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name=\"/Constant_13\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={128}, onnx_name=\"/Constant_14\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_15\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Slice_3_output_0 : Float(64, 128, strides=[128, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/Slice_3\"](%A, %/Constant_13_output_0, %/Constant_14_output_0, %/Constant_12_output_0, %/Constant_15_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_16\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_17\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_18_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name=\"/Constant_18\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_19_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_19\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Slice_4_output_0 : Float(64, 64, strides=[128, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/Slice_4\"](%/Slice_3_output_0, %/Constant_17_output_0, %/Constant_18_output_0, %/Constant_16_output_0, %/Constant_19_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_20_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_20\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_21_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name=\"/Constant_21\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_22_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={128}, onnx_name=\"/Constant_22\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_23\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Slice_5_output_0 : Float(64, 64, strides=[128, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/Slice_5\"](%/Slice_3_output_0, %/Constant_21_output_0, %/Constant_22_output_0, %/Constant_20_output_0, %/Constant_23_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:15:0\n",
      "  %/Constant_24_output_0 : Float(64, 64, strides=[1, 128], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_24\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/MatMul_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul\"](%/Slice_1_output_0, %/Constant_24_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Constant_25_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_25\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Add_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add\"](%/Constant_25_output_0, %/MatMul_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Constant_26_output_0 : Float(64, 64, strides=[1, 128], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_26\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/MatMul_1_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_1\"](%/Slice_2_output_0, %/Constant_26_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Add_1_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add_1\"](%/Add_output_0, %/MatMul_1_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Constant_27_output_0 : Float(64, 64, strides=[1, 128], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_27\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/MatMul_2_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_2\"](%/Slice_1_output_0, %/Constant_27_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Constant_28_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_28\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Add_2_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add_2\"](%/Constant_28_output_0, %/MatMul_2_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Constant_29_output_0 : Float(64, 64, strides=[1, 128], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_29\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/MatMul_3_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_3\"](%/Slice_2_output_0, %/Constant_29_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Add_3_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add_3\"](%/Add_2_output_0, %/MatMul_3_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Concat_output_0 : Float(64, 128, strides=[128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/Concat\"](%/Add_1_output_0, %/Add_3_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:32:0\n",
      "  %/Constant_30_output_0 : Float(64, 64, strides=[1, 128], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_30\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/MatMul_4_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_4\"](%/Slice_4_output_0, %/Constant_30_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Constant_31_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_31\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Add_4_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add_4\"](%/Constant_31_output_0, %/MatMul_4_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Constant_32_output_0 : Float(64, 64, strides=[1, 128], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_32\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/MatMul_5_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_5\"](%/Slice_5_output_0, %/Constant_32_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Add_5_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add_5\"](%/Add_4_output_0, %/MatMul_5_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Constant_33_output_0 : Float(64, 64, strides=[1, 128], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_33\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/MatMul_6_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_6\"](%/Slice_4_output_0, %/Constant_33_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Constant_34_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_34\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Add_6_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add_6\"](%/Constant_34_output_0, %/MatMul_6_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Constant_35_output_0 : Float(64, 64, strides=[1, 128], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_35\"](), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/MatMul_7_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul_7\"](%/Slice_5_output_0, %/Constant_35_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Add_7_output_0 : Float(64, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add_7\"](%/Add_6_output_0, %/MatMul_7_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:29:0\n",
      "  %/Concat_1_output_0 : Float(64, 128, strides=[128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/Concat_1\"](%/Add_5_output_0, %/Add_7_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:32:0\n",
      "  %89 : Float(128, 128, strides=[128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=0, onnx_name=\"/Concat_2\"](%/Concat_output_0, %/Concat_1_output_0), scope: __main__.my_param_layer:: # /tmp/ipykernel_181003/3727506568.py:34:0\n",
      "  return (%89)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('==================================================================================================================================================')\n",
    "print('= HW 2-3-2 create a subgraph (2) as shown in the above diagram for the subgraph (1)                                                              =')\n",
    "print('==================================================================================================================================================')\n",
    "torch.onnx.export(model, input, \"blocked_linear.onnx\", verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "popo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
